# Insurance Risk MLÂ 

Predict claim severity from raw policy & loss data, interpret the drivers, and surface insights in a oneâ€‘click Streamlit dashboard.  
Built as a showcase of how data science can save insurers $$ by triaging highâ€‘severity claims earlier and optimising reserving.

![Python](https://img.shields.io/badge/Python-3.9-blue) ![License](https://img.shields.io/badge/License-MIT-green)

---

## ğŸ“ˆÂ Key Features
| Stage | What it does | Tech |
|-------|--------------|------|
| **DataÂ prep** | Cleans & joins 188â€¯k rows of anonymised autoâ€‘claim data (Kaggle â€œAllstate Claims Severityâ€) | `pandas`, `pyarrow` |
| **Feature engineering** | Target encoding, interaction terms, holiday flags | `scikitâ€‘learn`, `category_encoders` |
| **Model** | Gradientâ€‘boosted trees (LightGBM) with Bayesian hyperâ€‘tuning | `lightgbm`, `optuna` |
| **Explainability** | Global + local SHAP values with plainâ€‘English summaries | `shap` |
| **Dashboard** | Upload a CSV â†’ get severity prediction bands, driver plots, and whatâ€‘if sliders | `streamlit` |
| **Deployment** | Dockerfile + GitHubÂ Actions push to AWSÂ ECR or Heroku | `docker`, `ghâ€‘actions` |

---

## QuickÂ Start

```bash
# 1. Clone repo & install
git clone https://github.com/<yourâ€‘handle>/insurance-risk-ml.git
cd insurance-risk-ml
conda env create -f environment.yml
conda activate insurance-risk-ml

# 2. Train model & evaluate
python src/train.py --config configs/base.yaml

# 3. Launch dashboard
streamlit run app/app.py
